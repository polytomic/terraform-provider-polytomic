// Code generated by Polytomic. DO NOT EDIT.
// edit connections.yaml and re-run go generate

package connections

import (
	"context"

	"github.com/hashicorp/terraform-plugin-framework/attr"
	"github.com/hashicorp/terraform-plugin-framework/datasource"
	"github.com/hashicorp/terraform-plugin-framework/datasource/schema"
	"github.com/hashicorp/terraform-plugin-framework/diag"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/mitchellh/mapstructure"
	"github.com/polytomic/terraform-provider-polytomic/internal/providerclient"
)

// Ensure provider defined types fully satisfy framework interfaces
var _ datasource.DataSource = &SnowflakeConnectionDataSource{}

// ExampleDataSource defines the data source implementation.
type SnowflakeConnectionDataSource struct {
	provider *providerclient.Provider
}

func (d *SnowflakeConnectionDataSource) Configure(ctx context.Context, req datasource.ConfigureRequest, resp *datasource.ConfigureResponse) {
	if provider := providerclient.GetProvider(req.ProviderData, resp.Diagnostics); provider != nil {
		d.provider = provider
	}
}

func (d *SnowflakeConnectionDataSource) Metadata(ctx context.Context, req datasource.MetadataRequest, resp *datasource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_snowflake_connection"
}

func (d *SnowflakeConnectionDataSource) Schema(ctx context.Context, req datasource.SchemaRequest, resp *datasource.SchemaResponse) {
	resp.Schema = schema.Schema{
		MarkdownDescription: ":meta:subcategory:Connections: Snowflake Connection",
		Attributes: map[string]schema.Attribute{
			"id": schema.StringAttribute{
				MarkdownDescription: "",
				Required:            true,
			},
			"organization": schema.StringAttribute{
				MarkdownDescription: "",
				Optional:            true,
			},
			"name": schema.StringAttribute{
				MarkdownDescription: "",
				Computed:            true,
			},
			"configuration": schema.SingleNestedAttribute{
				Attributes: map[string]schema.Attribute{
					"account": schema.StringAttribute{
						MarkdownDescription: `Account identifier

    e.g. FRXJLEC-UJA94780`,
						Computed: true,
					},
					"bulk_sync_staging_schema": schema.StringAttribute{
						MarkdownDescription: `Staging schema name`,
						Computed:            true,
					},
					"dbname": schema.StringAttribute{
						MarkdownDescription: `Database`,
						Computed:            true,
					},
					"key_pair_auth": schema.BoolAttribute{
						MarkdownDescription: `Use key pair authentication`,
						Computed:            true,
					},
					"params": schema.StringAttribute{
						MarkdownDescription: `Additional parameters

    Additional connection parameters, formatted as a query string`,
						Computed: true,
					},
					"use_bulk_sync_staging_schema": schema.BoolAttribute{
						MarkdownDescription: `Use custom bulk sync staging schema`,
						Computed:            true,
					},
					"username": schema.StringAttribute{
						MarkdownDescription: ``,
						Computed:            true,
					},
					"warehouse": schema.StringAttribute{
						MarkdownDescription: `Compute warehouse`,
						Computed:            true,
					},
				},
				Optional: true,
			},
		},
	}
}

type SnowflakeDataSourceConf struct {
	Account                      string `mapstructure:"account" tfsdk:"account"`
	Bulk_sync_staging_schema     string `mapstructure:"bulk_sync_staging_schema" tfsdk:"bulk_sync_staging_schema"`
	Dbname                       string `mapstructure:"dbname" tfsdk:"dbname"`
	Key_pair_auth                bool   `mapstructure:"key_pair_auth" tfsdk:"key_pair_auth"`
	Params                       string `mapstructure:"params" tfsdk:"params"`
	Use_bulk_sync_staging_schema bool   `mapstructure:"use_bulk_sync_staging_schema" tfsdk:"use_bulk_sync_staging_schema"`
	Username                     string `mapstructure:"username" tfsdk:"username"`
	Warehouse                    string `mapstructure:"warehouse" tfsdk:"warehouse"`
}

func (d *SnowflakeConnectionDataSource) Read(ctx context.Context, req datasource.ReadRequest, resp *datasource.ReadResponse) {
	var data connectionDataSourceData

	// Read Terraform configuration data into the model
	resp.Diagnostics.Append(req.Config.Get(ctx, &data)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Get the connection
	client, err := d.provider.Client(data.Organization.ValueString())
	if err != nil {
		resp.Diagnostics.AddError("Error getting client", err.Error())
		return
	}
	connection, err := client.Connections.Get(ctx, data.Id.ValueString())
	if err != nil {
		resp.Diagnostics.AddError("Error getting connection", err.Error())
		return
	}

	data.Id = types.StringPointerValue(connection.Data.Id)
	data.Name = types.StringPointerValue(connection.Data.Name)
	data.Organization = types.StringPointerValue(connection.Data.OrganizationId)

	conf := SnowflakeDataSourceConf{}
	err = mapstructure.Decode(connection.Data.Configuration, &conf)
	if err != nil {
		resp.Diagnostics.AddError("Error decoding connection configuration", err.Error())
		return
	}

	var diags diag.Diagnostics
	data.Configuration, diags = types.ObjectValueFrom(ctx, map[string]attr.Type{
		"account":                      types.StringType,
		"bulk_sync_staging_schema":     types.StringType,
		"dbname":                       types.StringType,
		"key_pair_auth":                types.BoolType,
		"params":                       types.StringType,
		"use_bulk_sync_staging_schema": types.BoolType,
		"username":                     types.StringType,
		"warehouse":                    types.StringType,
	}, conf)
	if diags.HasError() {
		resp.Diagnostics.Append(diags...)
		return
	}

	// Save data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}
