// Code generated by Polytomic. DO NOT EDIT.
// edit connections.yaml and re-run go generate

package connections

import (
	"context"

	"github.com/hashicorp/terraform-plugin-framework/attr"
	"github.com/hashicorp/terraform-plugin-framework/datasource"
	"github.com/hashicorp/terraform-plugin-framework/datasource/schema"
	"github.com/hashicorp/terraform-plugin-framework/diag"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/mitchellh/mapstructure"
	"github.com/polytomic/terraform-provider-polytomic/internal/providerclient"
)

// Ensure provider defined types fully satisfy framework interfaces
var _ datasource.DataSource = &GcsConnectionDataSource{}

// ExampleDataSource defines the data source implementation.
type GcsConnectionDataSource struct {
	provider *providerclient.Provider
}

func (d *GcsConnectionDataSource) Configure(ctx context.Context, req datasource.ConfigureRequest, resp *datasource.ConfigureResponse) {
	if provider := providerclient.GetProvider(req.ProviderData, resp.Diagnostics); provider != nil {
		d.provider = provider
	}
}

func (d *GcsConnectionDataSource) Metadata(ctx context.Context, req datasource.MetadataRequest, resp *datasource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_gcs_connection"
}

func (d *GcsConnectionDataSource) Schema(ctx context.Context, req datasource.SchemaRequest, resp *datasource.SchemaResponse) {
	resp.Schema = schema.Schema{
		MarkdownDescription: ":meta:subcategory:Connections: Google Cloud Storage Connection",
		Attributes: map[string]schema.Attribute{
			"id": schema.StringAttribute{
				MarkdownDescription: "",
				Required:            true,
			},
			"organization": schema.StringAttribute{
				MarkdownDescription: "",
				Optional:            true,
			},
			"name": schema.StringAttribute{
				MarkdownDescription: "",
				Computed:            true,
			},
			"configuration": schema.SingleNestedAttribute{
				Attributes: map[string]schema.Attribute{
					"bucket": schema.StringAttribute{
						MarkdownDescription: ``,
						Computed:            true,
					},
					"client_email": schema.StringAttribute{
						MarkdownDescription: `Service account identity`,
						Computed:            true,
					},
					"csv_has_headers": schema.BoolAttribute{
						MarkdownDescription: `CSV files have headers

    Whether CSV files have a header row with field names.`,
						Computed: true,
					},
					"directory_glob_pattern": schema.StringAttribute{
						MarkdownDescription: `Tables glob path`,
						Computed:            true,
					},
					"is_directory_snapshot": schema.BoolAttribute{
						MarkdownDescription: `Multi-directory multi-table`,
						Computed:            true,
					},
					"is_single_table": schema.BoolAttribute{
						MarkdownDescription: `Files are time-based snapshots

    Treat the files as a single table.`,
						Computed: true,
					},
					"project_id": schema.StringAttribute{
						MarkdownDescription: `Service account project ID`,
						Computed:            true,
					},
					"single_table_file_format": schema.StringAttribute{
						MarkdownDescription: `File format`,
						Computed:            true,
					},
					"single_table_file_formats": schema.SetAttribute{
						MarkdownDescription: `File formats

    File formats that may be present across different tables`,
						Computed:    true,
						ElementType: types.StringType,
					},
					"single_table_name": schema.StringAttribute{
						MarkdownDescription: `Collection name`,
						Computed:            true,
					},
					"skip_lines": schema.Int64Attribute{
						MarkdownDescription: `Skip first lines

    Skip first N lines of each CSV file.`,
						Computed: true,
					},
				},
				Optional: true,
			},
		},
	}
}

type GcsDataSourceConf struct {
	Bucket                    string   `mapstructure:"bucket" tfsdk:"bucket"`
	Client_email              string   `mapstructure:"client_email" tfsdk:"client_email"`
	Csv_has_headers           bool     `mapstructure:"csv_has_headers" tfsdk:"csv_has_headers"`
	Directory_glob_pattern    string   `mapstructure:"directory_glob_pattern" tfsdk:"directory_glob_pattern"`
	Is_directory_snapshot     bool     `mapstructure:"is_directory_snapshot" tfsdk:"is_directory_snapshot"`
	Is_single_table           bool     `mapstructure:"is_single_table" tfsdk:"is_single_table"`
	Project_id                string   `mapstructure:"project_id" tfsdk:"project_id"`
	Single_table_file_format  string   `mapstructure:"single_table_file_format" tfsdk:"single_table_file_format"`
	Single_table_file_formats []string `mapstructure:"single_table_file_formats" tfsdk:"single_table_file_formats"`
	Single_table_name         string   `mapstructure:"single_table_name" tfsdk:"single_table_name"`
	Skip_lines                int64    `mapstructure:"skip_lines" tfsdk:"skip_lines"`
}

func (d *GcsConnectionDataSource) Read(ctx context.Context, req datasource.ReadRequest, resp *datasource.ReadResponse) {
	var data connectionDataSourceData

	// Read Terraform configuration data into the model
	resp.Diagnostics.Append(req.Config.Get(ctx, &data)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Get the connection
	client, err := d.provider.Client(data.Organization.ValueString())
	if err != nil {
		resp.Diagnostics.AddError("Error getting client", err.Error())
		return
	}
	connection, err := client.Connections.Get(ctx, data.Id.ValueString())
	if err != nil {
		resp.Diagnostics.AddError("Error getting connection", err.Error())
		return
	}

	data.Id = types.StringPointerValue(connection.Data.Id)
	data.Name = types.StringPointerValue(connection.Data.Name)
	data.Organization = types.StringPointerValue(connection.Data.OrganizationId)

	conf := GcsDataSourceConf{}
	err = mapstructure.Decode(connection.Data.Configuration, &conf)
	if err != nil {
		resp.Diagnostics.AddError("Error decoding connection configuration", err.Error())
		return
	}

	var diags diag.Diagnostics
	data.Configuration, diags = types.ObjectValueFrom(ctx, map[string]attr.Type{
		"bucket":                   types.StringType,
		"client_email":             types.StringType,
		"csv_has_headers":          types.BoolType,
		"directory_glob_pattern":   types.StringType,
		"is_directory_snapshot":    types.BoolType,
		"is_single_table":          types.BoolType,
		"project_id":               types.StringType,
		"single_table_file_format": types.StringType,
		"single_table_file_formats": types.SetType{
			ElemType: types.StringType,
		},
		"single_table_name": types.StringType,
		"skip_lines":        types.NumberType,
	}, conf)
	if diags.HasError() {
		resp.Diagnostics.Append(diags...)
		return
	}

	// Save data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}
