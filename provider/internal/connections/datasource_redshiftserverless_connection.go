// Code generated by Polytomic. DO NOT EDIT.
// edit connections.yaml and re-run go generate

package connections

import (
	"context"

	"github.com/hashicorp/terraform-plugin-framework/attr"
	"github.com/hashicorp/terraform-plugin-framework/datasource"
	"github.com/hashicorp/terraform-plugin-framework/datasource/schema"
	"github.com/hashicorp/terraform-plugin-framework/diag"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/mitchellh/mapstructure"
	"github.com/polytomic/terraform-provider-polytomic/internal/providerclient"
)

// Ensure provider defined types fully satisfy framework interfaces
var _ datasource.DataSource = &RedshiftserverlessConnectionDataSource{}

// ExampleDataSource defines the data source implementation.
type RedshiftserverlessConnectionDataSource struct {
	provider *providerclient.Provider
}

func (d *RedshiftserverlessConnectionDataSource) Configure(ctx context.Context, req datasource.ConfigureRequest, resp *datasource.ConfigureResponse) {
	if provider := providerclient.GetProvider(req.ProviderData, resp.Diagnostics); provider != nil {
		d.provider = provider
	}
}

func (d *RedshiftserverlessConnectionDataSource) Metadata(ctx context.Context, req datasource.MetadataRequest, resp *datasource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_redshiftserverless_connection"
}

func (d *RedshiftserverlessConnectionDataSource) Schema(ctx context.Context, req datasource.SchemaRequest, resp *datasource.SchemaResponse) {
	resp.Schema = schema.Schema{
		MarkdownDescription: ":meta:subcategory:Connections: Redshift Serverless Connection",
		Attributes: map[string]schema.Attribute{
			"id": schema.StringAttribute{
				MarkdownDescription: "",
				Required:            true,
			},
			"organization": schema.StringAttribute{
				MarkdownDescription: "",
				Optional:            true,
			},
			"name": schema.StringAttribute{
				MarkdownDescription: "",
				Computed:            true,
			},
			"configuration": schema.SingleNestedAttribute{
				Attributes: map[string]schema.Attribute{
					"bulk_sync_staging_schema": schema.StringAttribute{
						MarkdownDescription: `Staging schema name`,
						Computed:            true,
					},
					"connection_method": schema.StringAttribute{
						MarkdownDescription: `Connection method`,
						Computed:            true,
					},
					"data_api_endpoint": schema.StringAttribute{
						MarkdownDescription: `Redshift Data API endpoint

    Example: https://redshift-data.us-west-2.amazonaws.com`,
						Computed: true,
					},
					"database": schema.StringAttribute{
						MarkdownDescription: ``,
						Computed:            true,
					},
					"endpoint": schema.StringAttribute{
						MarkdownDescription: `Redshift Serverless endpoint`,
						Computed:            true,
					},
					"external_id": schema.StringAttribute{
						MarkdownDescription: `External ID`,
						Computed:            true,
					},
					"iam_role_arn": schema.StringAttribute{
						MarkdownDescription: `IAM Role ARN`,
						Computed:            true,
					},
					"override_endpoint": schema.BoolAttribute{
						MarkdownDescription: `Override Redshift Data API endpoint`,
						Computed:            true,
					},
					"region": schema.StringAttribute{
						MarkdownDescription: ``,
						Computed:            true,
					},
					"s3_bucket_name": schema.StringAttribute{
						MarkdownDescription: `S3 bucket name (destination/unload support only)`,
						Computed:            true,
					},
					"s3_bucket_region": schema.StringAttribute{
						MarkdownDescription: `S3 bucket region (destination/unload support only)`,
						Computed:            true,
					},
					"use_bulk_sync_staging_schema": schema.BoolAttribute{
						MarkdownDescription: `Use custom bulk sync staging schema`,
						Computed:            true,
					},
					"use_unload": schema.BoolAttribute{
						MarkdownDescription: `Read data using Unload`,
						Computed:            true,
					},
					"workgroup": schema.StringAttribute{
						MarkdownDescription: ``,
						Computed:            true,
					},
				},
				Optional: true,
			},
		},
	}
}

type RedshiftserverlessDataSourceConf struct {
	Bulk_sync_staging_schema     string `mapstructure:"bulk_sync_staging_schema" tfsdk:"bulk_sync_staging_schema"`
	Connection_method            string `mapstructure:"connection_method" tfsdk:"connection_method"`
	Data_api_endpoint            string `mapstructure:"data_api_endpoint" tfsdk:"data_api_endpoint"`
	Database                     string `mapstructure:"database" tfsdk:"database"`
	Endpoint                     string `mapstructure:"endpoint" tfsdk:"endpoint"`
	External_id                  string `mapstructure:"external_id" tfsdk:"external_id"`
	Iam_role_arn                 string `mapstructure:"iam_role_arn" tfsdk:"iam_role_arn"`
	Override_endpoint            bool   `mapstructure:"override_endpoint" tfsdk:"override_endpoint"`
	Region                       string `mapstructure:"region" tfsdk:"region"`
	S3_bucket_name               string `mapstructure:"s3_bucket_name" tfsdk:"s3_bucket_name"`
	S3_bucket_region             string `mapstructure:"s3_bucket_region" tfsdk:"s3_bucket_region"`
	Use_bulk_sync_staging_schema bool   `mapstructure:"use_bulk_sync_staging_schema" tfsdk:"use_bulk_sync_staging_schema"`
	Use_unload                   bool   `mapstructure:"use_unload" tfsdk:"use_unload"`
	Workgroup                    string `mapstructure:"workgroup" tfsdk:"workgroup"`
}

func (d *RedshiftserverlessConnectionDataSource) Read(ctx context.Context, req datasource.ReadRequest, resp *datasource.ReadResponse) {
	var data connectionDataSourceData

	// Read Terraform configuration data into the model
	resp.Diagnostics.Append(req.Config.Get(ctx, &data)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Get the connection
	client, err := d.provider.Client(data.Organization.ValueString())
	if err != nil {
		resp.Diagnostics.AddError("Error getting client", err.Error())
		return
	}
	connection, err := client.Connections.Get(ctx, data.Id.ValueString())
	if err != nil {
		resp.Diagnostics.AddError("Error getting connection", err.Error())
		return
	}

	data.Id = types.StringPointerValue(connection.Data.Id)
	data.Name = types.StringPointerValue(connection.Data.Name)
	data.Organization = types.StringPointerValue(connection.Data.OrganizationId)

	conf := RedshiftserverlessDataSourceConf{}
	err = mapstructure.Decode(connection.Data.Configuration, &conf)
	if err != nil {
		resp.Diagnostics.AddError("Error decoding connection configuration", err.Error())
		return
	}

	var diags diag.Diagnostics
	data.Configuration, diags = types.ObjectValueFrom(ctx, map[string]attr.Type{
		"bulk_sync_staging_schema":     types.StringType,
		"connection_method":            types.StringType,
		"data_api_endpoint":            types.StringType,
		"database":                     types.StringType,
		"endpoint":                     types.StringType,
		"external_id":                  types.StringType,
		"iam_role_arn":                 types.StringType,
		"override_endpoint":            types.BoolType,
		"region":                       types.StringType,
		"s3_bucket_name":               types.StringType,
		"s3_bucket_region":             types.StringType,
		"use_bulk_sync_staging_schema": types.BoolType,
		"use_unload":                   types.BoolType,
		"workgroup":                    types.StringType,
	}, conf)
	if diags.HasError() {
		resp.Diagnostics.Append(diags...)
		return
	}

	// Save data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}
